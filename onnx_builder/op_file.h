LSTM=float clip;, int direction;, int hidden_size;, int input_forget;
Identity=
Abs=
BatchNormalization=float epsilon;, float momentum;
Mean=
Add=
GlobalMaxPool=
Cast=int to;
AveragePool=Shape_t kernel_shape;, int auto_pad;, int ceil_mode;, int count_include_pad;, Shape_t pads;, Shape_t strides;
And=
LRN=int size;, float alpha;, float beta;, float bias;
ArgMax=int axis;, int keepdims;
Resize=int mode;
Expand=
Neg=
Mul=
ArgMin=int axis;, int keepdims;
CastMap=int cast_to;, int map_form;, int max_map;
Exp=
Div=
ReverseSequence=int batch_axis;, int time_axis;
Ceil=
DepthToSpace=int blocksize;
Clip=float max;, float min;
RNN=float clip;, int direction;, int hidden_size;
Concat=int axis;
Constant=
LpPool=Shape_t kernel_shape;, int auto_pad;, int p;, Shape_t pads;, Shape_t strides;
Conv=int auto_pad;, Shape_t dilations;, int group;, Shape_t kernel_shape;, Shape_t pads;, Shape_t strides;
Not=
Gather=int axis;
ConvTranspose=int auto_pad;, Shape_t dilations;, int group;, Shape_t kernel_shape;, Shape_t output_padding;, Shape_t output_shape;, Shape_t pads;, Shape_t strides;
Dropout=float ratio;
LeakyRelu=float alpha;
Elu=float alpha;
GlobalAveragePool=
Gemm=float alpha;, float beta;, int transA;, int transB;
MaxPool=Shape_t kernel_shape;, int auto_pad;, int ceil_mode;, Shape_t dilations;, Shape_t pads;, int storage_order;, Shape_t strides;
Equal=
Tile=
Flatten=int axis;
Floor=
GRU=float clip;, int direction;, int hidden_size;, int linear_before_reset;
GlobalLpPool=int p;
Greater=
HardSigmoid=float alpha;, float beta;
Selu=float alpha;, float gamma;
Hardmax=int axis;
If=int else_branch;, int then_branch;
Min=
InstanceNormalization=float epsilon;
Less=
EyeLike=int dtype;, int k;
RandomNormal=Shape_t shape;, int dtype;, float mean;, float scale;, float seed;
Slice=
PRelu=
Log=
LogSoftmax=int axis;
Loop=int body;
LpNormalization=int axis;, int p;
MatMul=
ReduceL2=Shape_t axes;, int keepdims;
Max=
MaxRoiPool=Shape_t pooled_shape;, float spatial_scale;
Or=
Pad=Shape_t pads;, int mode;, float value;
RandomUniformLike=int dtype;, float high;, float low;, float seed;
Reciprocal=
Pow=
RandomNormalLike=int dtype;, float mean;, float scale;, float seed;
OneHot=int axis;
RandomUniform=Shape_t shape;, int dtype;, float high;, float low;, float seed;
ReduceL1=Shape_t axes;, int keepdims;
ReduceLogSum=Shape_t axes;, int keepdims;
ReduceLogSumExp=Shape_t axes;, int keepdims;
ReduceMax=Shape_t axes;, int keepdims;
OneHotEncoder=Shape_t cats_int64s;, int zeros;
IsNaN=
ReduceMean=Shape_t axes;, int keepdims;
ReduceMin=Shape_t axes;, int keepdims;
TreeEnsembleRegressor=int aggregate_function;, int n_targets;, Shape_t nodes_falsenodeids;, Shape_t nodes_featureids;, Shape_t nodes_missing_value_tracks_true;, Shape_t nodes_nodeids;, Shape_t nodes_treeids;, Shape_t nodes_truenodeids;, int post_transform;, Shape_t target_ids;, Shape_t target_nodeids;, Shape_t target_treeids;
ReduceProd=Shape_t axes;, int keepdims;
ReduceSum=Shape_t axes;, int keepdims;
ReduceSumSquare=Shape_t axes;, int keepdims;
Relu=
Reshape=
Shape=
Sigmoid=
Size=
Softmax=int axis;
Softplus=
Softsign=
SpaceToDepth=int blocksize;
TfIdfVectorizer=int max_gram_length;, int max_skip_count;, int min_gram_length;, int mode;, Shape_t ngram_counts;, Shape_t ngram_indexes;, Shape_t pool_int64s;
Split=int axis;, Shape_t split;
Imputer=Shape_t imputed_value_int64s;, float replaced_value_float;, int replaced_value_int64;
Sqrt=
Squeeze=Shape_t axes;
TopK=int axis;
Sub=
Sum=
Shrink=float bias;, float lambd;
Tanh=
Transpose=Shape_t perm;
Unsqueeze=Shape_t axes;
Upsample=int mode;
SVMClassifier=Shape_t classlabels_ints;, int kernel_type;, int post_transform;, Shape_t vectors_per_class;
Xor=
Acos=
Asin=
Atan=
Cos=
Sin=
Tan=
Multinomial=int dtype;, int sample_size;, float seed;
Scan=int body;, int num_scan_inputs;, Shape_t scan_input_axes;, Shape_t scan_input_directions;, Shape_t scan_output_axes;, Shape_t scan_output_directions;
Compress=int axis;
ConstantOfShape=
MaxUnpool=Shape_t kernel_shape;, Shape_t pads;, Shape_t strides;
Scatter=int axis;
Sinh=
Cosh=
Asinh=
Acosh=
NonMaxSuppression=int center_point_box;
Atanh=
Sign=
Erf=
Where=
NonZero=
MeanVarianceNormalization=Shape_t axes;
StringNormalizer=int case_change_action;, int is_case_sensitive;, int locale;
Mod=int fmod;
ThresholdedRelu=float alpha;
MatMulInteger=
QLinearMatMul=
ConvInteger=int auto_pad;, Shape_t dilations;, int group;, Shape_t kernel_shape;, Shape_t pads;, Shape_t strides;
QLinearConv=int auto_pad;, Shape_t dilations;, int group;, Shape_t kernel_shape;, Shape_t pads;, Shape_t strides;
QuantizeLinear=
DequantizeLinear=
IsInf=int detect_negative;, int detect_positive;
RoiAlign=int mode;, int output_height;, int output_width;, int sampling_ratio;, float spatial_scale;
ArrayFeatureExtractor=
Binarizer=float threshold;
CategoryMapper=Shape_t cats_int64s;, int default_int64;, int default_string;
DictVectorizer=Shape_t int64_vocabulary;
FeatureVectorizer=Shape_t inputdimensions;
LabelEncoder=float default_float;, int default_int64;, int default_string;, Shape_t keys_int64s;, Shape_t values_int64s;
LinearClassifier=Shape_t classlabels_ints;, int multi_class;, int post_transform;
LinearRegressor=int post_transform;, int targets;
Normalizer=int norm;
SVMRegressor=int kernel_type;, int n_supports;, int one_class;, int post_transform;
Scaler=
TreeEnsembleClassifier=Shape_t class_ids;, Shape_t class_nodeids;, Shape_t class_treeids;, Shape_t classlabels_int64s;, Shape_t nodes_falsenodeids;, Shape_t nodes_featureids;, Shape_t nodes_missing_value_tracks_true;, Shape_t nodes_nodeids;, Shape_t nodes_treeids;, Shape_t nodes_truenodeids;, int post_transform;
ZipMap=Shape_t classlabels_int64s;
